{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camID: (14096,)\n",
      "filelist: (14096,)\n",
      "gallery_idx: (5328,)\n",
      "labels: (14096,)\n",
      "query_idx: (1400,)\n",
      "train_idx: (7368,)\n"
     ]
    }
   ],
   "source": [
    "data = loadmat('PR_data/cuhk03_new_protocol_config_labeled.mat')\n",
    "camID = data['camId'].flatten()\n",
    "filelist = data['filelist'].flatten()\n",
    "gallery_idx = data['gallery_idx'].flatten()\n",
    "labels = data['labels'].flatten()\n",
    "query_idx = data['query_idx'].flatten()\n",
    "train_idx = data['train_idx'].flatten()\n",
    "\n",
    "print('camID:',camID.shape)\n",
    "print('filelist:',filelist.shape)\n",
    "print('gallery_idx:',gallery_idx.shape)\n",
    "print('labels:',labels.shape)\n",
    "print('query_idx:',query_idx.shape)\n",
    "print('train_idx:',train_idx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   UNCOMMENT!!!!!!!!!!!!1\n",
    "with open('PR_data/feature_data.json','r')as f:\n",
    "    features = json.load(f)\n",
    "print(len(features), len(features[0]))\n",
    "\n",
    "features = np.asarray(features) # each row is a feature (data instance)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.mat does not exist.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\koral\\.virtualenvs\\ee4-68_pr_cw_2-_piv1eq7\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PR_data/features.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bf618ed91913>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PR_data/features.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\koral\\.virtualenvs\\ee4-68_pr_cw_2-_piv1eq7\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\koral\\.virtualenvs\\ee4-68_pr_cw_2-_piv1eq7\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[1;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mbyte_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\koral\\.virtualenvs\\ee4-68_pr_cw_2-_piv1eq7\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat)\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PR_data/features.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-bf618ed91913>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'features.mat does not exist.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PR_data/feature_data.json'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# each row is a feature (data instance) print(features.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\koral\\appdata\\local\\programs\\python\\python37-32\\Lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m     return loads(fp.read(),\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    features = loadmat('PR_data/features.mat')\n",
    "    features = features['features']\n",
    "except FileNotFoundError:\n",
    "    print('features.mat does not exist.')\n",
    "    with open('PR_data/feature_data.json','r')as f:\n",
    "        features = json.load(f)\n",
    "        features = np.asarray(features) # each row is a feature (data instance) print(features.shape)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767\n",
      "6601\n"
     ]
    }
   ],
   "source": [
    "train = features[train_idx-1]\n",
    "tLabels = labels[train_idx-1]\n",
    "query = features[query_idx-1]\n",
    "qLabels = labels[query_idx-1]\n",
    "gallery = features[gallery_idx-1]\n",
    "gLabels = labels[gallery_idx-1]\n",
    "tID = camID[train_idx-1]\n",
    "qID = camID[query_idx-1]\n",
    "gID = camID[gallery_idx-1]\n",
    "\n",
    "c = len(np.unique(tLabels)) #767\n",
    "print(c)\n",
    "\n",
    "print(len(train)-c) # 6601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, training_dataset, query_dataset, gallery_dataset):\n",
    "    model = model.fit(training_dataset.features_array(), training_dataset.labels())\n",
    "    omega_query = model.transform(query_dataset.features_array())\n",
    "    omega_gallery = model.transform(gallery_dataset.features_array())\n",
    "    \n",
    "    return model, omega_query, omega_gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working\n"
     ]
    }
   ],
   "source": [
    "def kNN(k,query,qLabels,qID,gallery,gLabels,gID,metric):\n",
    "    G = [] #list of lists, #list = #query imgs, length of each list = #gallery imgs used\n",
    "    for i in range(len(query)):\n",
    "        #indices for gallery features to use\n",
    "        G.append([x for x in range(len(gallery)) if not(gLabels[x]==qLabels[i] and gID[x]==qID[i])]) \n",
    "    print('G')\n",
    "    \n",
    "    sorted_idx = []\n",
    "    for i in range(len(query)):\n",
    "        Dist = distance.cdist(np.reshape(query[i],(1,-1)),gallery[G[i]],metric = metric)\n",
    "        sorted_idx.append(np.argsort(Dist))\n",
    "    print('sorted_idx')\n",
    "\n",
    "    def accuracy(k):\n",
    "        NN = [arr[0,:k] for arr in sorted_idx]\n",
    "\n",
    "        sum = 0\n",
    "        for i in range(len(query)):\n",
    "            usedLabels = gLabels[G[i]] # labels of gallery images used for each query image\n",
    "            if(qLabels[i] in usedLabels[NN[i]]): \n",
    "                sum += 1\n",
    "        acc = sum/len(query)\n",
    "        return acc\n",
    "    print('NN')\n",
    "    \n",
    "    if type(k) is list:\n",
    "        acc = []\n",
    "        for n in k:\n",
    "            acc.append(accuracy(n))\n",
    "    else:\n",
    "        acc = accuracy(k)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "print('working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datapoint(object):\n",
    "    def __init__(self, features, label, cam_id):\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "        self.cam_id = cam_id\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, datapoint_list):\n",
    "        self.datapoints = datapoint_list\n",
    "    \n",
    "    def features_array(self):\n",
    "        return np.array([datapoint.features for datapoint in self.datapoints])\n",
    "    def labels(self):\n",
    "        return np.array([datapoint.label for datapoint in self.datapoints])\n",
    "    def cam_ids(self):\n",
    "        return np.array([datapoint.cam_id for datapoint in self.datapoints])\n",
    "\n",
    "training_dataset = Dataset([Datapoint(train[i], tLabels[i], tID[i]) for i in range(len(train))])\n",
    "query_dataset = Dataset([Datapoint(query[i], qLabels[i], qID[i]) for i in range(len(query))])\n",
    "gallery_dataset = Dataset([Datapoint(gallery[i], gLabels[i], gID[i]) for i in range(len(gallery))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2048)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9786373907490166"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_pca = 300\n",
    "\n",
    "pca = PCA(n_components=M_pca)\n",
    "pca, omega_q_pca, omega_g_pca = fit_model(pca, training_dataset, query_dataset, gallery_dataset)\n",
    "w_pca = pca.components_\n",
    "print(w_pca.shape)\n",
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 2048)\n",
      "0.7723529685691517\n",
      "(1400, 300) (5328, 300)\n"
     ]
    }
   ],
   "source": [
    "M_lda = 300\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=M_lda)\n",
    "lda, omega_q_lda, omega_g_lda = fit_model(lda, training_dataset, query_dataset, gallery_dataset) #(1400,Mlda),(5328,M_pca)\n",
    "w_lda = lda.coef_[:M_lda,:]\n",
    "print(w_lda.shape)\n",
    "print(np.sum(lda.explained_variance_ratio_))\n",
    "print(omega_q_lda.shape,omega_g_lda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_opt = w_opt = np.dot(w_lda.T,w_pca.T).T\n",
    "print(w_opt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G\n",
      "sorted_idx\n",
      "NN\n",
      "pca: [0.4685714285714286, 0.5464285714285714, 0.5942857142857143, 0.6728571428571428, 0.7492857142857143, 0.83, 0.8971428571428571, 0.9321428571428572, 0.9457142857142857]\n",
      "G\n",
      "sorted_idx\n",
      "NN\n",
      "lda: [0.4278571428571429, 0.4957142857142857, 0.5535714285714286, 0.6257142857142857, 0.7107142857142857, 0.7921428571428571, 0.8678571428571429, 0.8985714285714286, 0.9185714285714286]\n"
     ]
    }
   ],
   "source": [
    "acc_pca = kNN(k = [1,2,3,5,10,20,50,75,100],query=omega_q_pca,qLabels=qLabels,qID=qID,gallery=omega_g_pca,\n",
    "          gLabels=gLabels,gID=gID,metric='euclidean')\n",
    "print('pca:',acc_pca)\n",
    "\n",
    "acc_lda = kNN(k = [1,2,3,5,10,20,50,75,100],query=omega_q_lda,qLabels=qLabels,qID=qID,gallery=omega_g_lda,\n",
    "          gLabels=gLabels,gID=gID,metric='euclidean')\n",
    "print('lda:',acc_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.73728041e-17  4.85677369e-16 -3.28817682e-16 ... -3.55849986e-16\n",
      "  3.75438611e-16  1.89497350e-16]\n"
     ]
    }
   ],
   "source": [
    "# standardise the features\n",
    "\n",
    "train_std = StandardScaler().fit_transform(train)\n",
    "gallery_std = StandardScaler().fit_transform(gallery)\n",
    "print(np.sum(train_std,axis = 0)/len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
